{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "676E3VDaeEqM",
        "4L4bkkOGeIrE",
        "fV5HekSegEU7"
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 60行の `numpy` で学ぶGPT"
      ],
      "metadata": {
        "id": "WAPkSnO-IdLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 入力 / 出力"
      ],
      "metadata": {
        "id": "676E3VDaeEqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# def <関数名>(<変数名>: <型>) -> <戻り値の型>:\n",
        "def gpt(inputs: list[int]) -> list[list[float]]:\n",
        "  # inputs は [n_seq] の形状を持つ\n",
        "  # 出力は [n_seq, n_vocab] の形状を持つ\n",
        "\n",
        "  vocab = [\"all\", \"not\", \"heroes\", \"the\", \"wear\", \".\", \"capes\"]\n",
        "  iputs = [1, 0, 2, 4] # \"not\" \"all\" \"heroes\" \"wear\"\n",
        "  output = gpt(inputs) # beep boop neural networkの魔法\n",
        "  next_token_id = np.aragmax(output[-1]) # next_token_id = 6\n",
        "  next_token = vocab[next_token_id] # next_token =\"capes\"\n",
        "  # 次のトークン予測を行っている\n",
        "  return output\n",
        "  ```"
      ],
      "metadata": {
        "id": "0Rh5cx7iFlwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### テキストの生成"
      ],
      "metadata": {
        "id": "4L4bkkOGeIrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# トークン予測を繰り返し取得することで、完全な分を生成する。各反復で、予測されたトークンを入力に追加し戻す。\n",
        "def generate(inputs, n_tokens_to_generate):\n",
        "  for _ in range(n_tokens_to_generate): # 自己回帰的でコードループ\n",
        "    outpu = gpt(inputs) # モデルのフォワードパス\n",
        "    next_id = np.argmax(output[-1]) # 貪欲サンプリング\n",
        "    inputs.append(int(next_id)) # 予測を入力に追加\n",
        "  return inputs[len(inputs) - n_tokens_to_generate :] # 生成されたIDのみを返す\n",
        "  ```\n",
        "この将来の値を予測し（回帰）、それを入力に追加する（自己）、というプロセスが、GPTを**自己回帰**と表現する理由"
      ],
      "metadata": {
        "id": "bpAPJChhfojb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### トレーニング"
      ],
      "metadata": {
        "id": "fV5HekSegEU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "def lm_loss(inputs: list[int], params) -> float:\n",
        "    # ラベルyは単に入力を1つ左にシフトしたものです。\n",
        "    #\n",
        "    # inputs = [not,     all,   heros,   wear,   capes]\n",
        "    #      x = [not,     all,   heroes,  wear]\n",
        "    #      y = [all,  heroes,     wear,  capes]\n",
        "    #\n",
        "    # もちろん、inputs[-1]に対するラベルはありませんので、xから除外します。\n",
        "    #\n",
        "    # そのため、N個の入力に対して、N - 1個の言語モデリング例のペアがあります。\n",
        "    x, y = inputs[:-1], inputs[1:]\n",
        "    # x: lower = 0, upper = N-1 の要素まで\n",
        "    # y: lower = 1, upper = 末尾の要素まで\n",
        "\n",
        "    # フォワードパス\n",
        "    # 各位置における予測された次のトークンの確率分布\n",
        "    output = gpt(x, params)\n",
        "\n",
        "    # クロスエントロピー損失\n",
        "    # 全てのN-1例についての平均を取ります。\n",
        "    loss = np.mean(-np.log(output[y]))\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train(texts: list[list[str]], params) -> float:\n",
        "    for text in texts:\n",
        "        inputs = tokenizer.encode(text)\n",
        "        loss = lm_loss(inputs, params)\n",
        "        gradients = compute_gradients_via_backpropagation(loss, params)\n",
        "        params = gradient_descent_update_step(gradients, params)\n",
        "    return params\n",
        "```"
      ],
      "metadata": {
        "id": "twTUtszAFv1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"blue\">セットアップ ここからがpicoGPTの実装</font>"
      ],
      "metadata": {
        "id": "YvA91tKOpBNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 必要なパッケージをインスト―ル\n",
        "- `fire`：Google製のlibraryです。「**コマンドラインからオブジェクトを自由に操作**」できるようになります。  \n",
        "  詳細については[こちらを参照](https://qiita.com/SaitoTsutomu/items/a5eb827737c9d59af2af)"
      ],
      "metadata": {
        "id": "EdwFS-uMdglh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fire"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeFftknlcLtE",
        "outputId": "2b8227df-954e-477e-a5ed-ab530ce50e8f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- google driveのマウント"
      ],
      "metadata": {
        "id": "xcUWC6TMjNR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhRMlVHgh7Bj",
        "outputId": "de7ec58a-e8d1-4b4d-dc1a-c8e41aa96d45"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- driveのマウント後であれば左のタブバーから**ファイルのパスのコピー**が可能  \n",
        "[参考](https://qiita.com/kado_u/items/45b76f9a6f920bf0f786)"
      ],
      "metadata": {
        "id": "1n6em1JHjbuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " cd /content/drive/MyDrive/データサイエンス/picoGPT/picoGPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEP_i9b4jSGv",
        "outputId": "5ea3a1ba-cd3e-4f40-a2bd-1bb70b40b0f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/データサイエンス/picoGPT/picoGPT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 依存関係のインストール"
      ],
      "metadata": {
        "id": "f-DT0d0AkG_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpI_JlKHhc4W",
        "outputId": "186f233b-6d06-4479-976e-19e4ca52d3b4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignoring tensorflow-macos: markers 'sys_platform == \"darwin\" and platform_machine == \"arm64\"' don't match your environment\n",
            "Requirement already satisfied: numpy==1.24.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.24.1)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.27.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.27.1)\n",
            "Requirement already satisfied: tqdm==4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.64.0)\n",
            "Requirement already satisfied: fire==0.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.5.0)\n",
            "Requirement already satisfied: tensorflow==2.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.11.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->-r requirements.txt (line 3)) (1.26.19)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->-r requirements.txt (line 3)) (2024.7.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->-r requirements.txt (line 3)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.27.1->-r requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire==0.5.0->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire==0.5.0->-r requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (3.9.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (2.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (24.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0->-r requirements.txt (line 9)) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0->-r requirements.txt (line 9)) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->-r requirements.txt (line 9)) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "YEOoGmmrlU8v"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def gpt2(inputs, wte, wpe, blocks, ln_f, n_head):\n",
        "   pass # TODO: これを実装する\n",
        "\n",
        "\n",
        "def generate(inputs, params, n_head, n_tokens_to_generate):\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    for _ in tqdm(range(n_tokens_to_generate), \"generating\"):  # 自己回帰デコードループ\n",
        "        logits = gpt2(inputs, **params, n_head=n_head)  # モデルのフォワードパス\n",
        "        next_id = np.argmax(logits[-1])  # 貪欲サンプリング\n",
        "        inputs.append(int(next_id))  # 予測を入力に追加\n",
        "\n",
        "    return inputs[len(inputs) - n_tokens_to_generate :]  # 生成されたidのみを返す\n",
        "\n",
        "\n",
        "def main(prompt: str, n_tokens_to_generate: int = 40, model_size: str = \"124M\", models_dir: str = \"models\"):\n",
        "    from utils import load_encoder_hparams_and_params\n",
        "\n",
        "    # 公開されているOpenAI GPT-2ファイルからエンコーダー、hparams、およびparamsを読み込む\n",
        "    encoder, hparams, params = load_encoder_hparams_and_params(model_size, models_dir)\n",
        "\n",
        "    # BPEトークナイザーを使用して入力文字列をエンコードする\n",
        "    input_ids = encoder.encode(prompt)\n",
        "\n",
        "    # モデルの最大シーケンス長を超えないようにする\n",
        "    assert len(input_ids) + n_tokens_to_generate < hparams[\"n_ctx\"]\n",
        "\n",
        "    # 出力idを生成する\n",
        "    output_ids = generate(input_ids, params, hparams[\"n_head\"], n_tokens_to_generate)\n",
        "\n",
        "    # idを文字列にデコードする\n",
        "    output_text = encoder.decode(output_ids)\n",
        "\n",
        "    return output_text\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import fire\n",
        "\n",
        "    fire.Fire(main)\n",
        "```"
      ],
      "metadata": {
        "id": "cM6_tI5PtVRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHwBzW40a-3G",
        "outputId": "cbdcc9c2-4ed9-469a-90af-0ec726d65abf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: utils in /usr/local/lib/python3.10/dist-packages (1.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import load_encoder_hparams_and_params\n",
        "encoder, hparams, params = load_encoder_hparams_and_params(\"124M\", \"models\")"
      ],
      "metadata": {
        "id": "IbbD4RcZZmtM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## エンコーダー"
      ],
      "metadata": {
        "id": "lHd0DC3nLLvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`encoder`はGPT-2で使用されるBPEトークナイザー：  \n",
        "```python\n",
        ">>> ids = encoder.encode(\"Not all heroes wear capes.\")  \n",
        ">>> ids  \n",
        "[3673, 477, 10281, 5806, 1451, 274, 13]\n",
        "```\n",
        "```python\n",
        ">>> encoder.decode(ids)  \n",
        "\"Not all heroes wear capes.\"  \n",
        "```\n",
        "トークナイザーの語彙(encoder.decoder`に保存されてる)を使用して、実際のトークンがどのように見えるかを確認できる：\n",
        "```python\n",
        ">>> [encoder.decoder[i] for i in ids]  \n",
        "['Not', 'Ġall', 'Ġheroes', 'Ġwear', 'Ġcap', 'es', '.']  \n",
        "```\n",
        "トークンは時には単語であり（例：Not）、時にはその前にスペースがある単語であることもあります（例：Ġall、Ġ はスペースを表します）、時には単語の一部であることもあります（例：capes は Ġcap と es に分割されます）、そして時には句読点であることもあります（例：.）。  \n",
        "\n",
        "BPEの良い点の一つは、任意の文字列をエンコードできること。語彙にない何かに出会った場合、それを理解できるサブストリングに分解する：\n",
        "```python\n",
        ">>> [encoder.decoder[i] for i in encoder.encode(\"zjqfl\")]  \n",
        "['z', 'j', 'q', 'fl']  \n",
        "```\n",
        "また、語彙のサイズも確認できる：\n",
        "```python\n",
        ">>> len(encoder.decoder)  \n",
        "50257\n",
        "```"
      ],
      "metadata": {
        "id": "MLtQ-X5WkUKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータ"
      ],
      "metadata": {
        "id": "Ocs0RoaumEpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`hparams`は、モデルのハイパーパラメータを含む辞書：\n",
        "```python\n",
        ">>> hparams  \n",
        "{  \n",
        "\"n_vocab\": 50257, # 語彙のトークン数  \n",
        "\"n_ctx\": 1024, # 入力の最大可能なシーケンス長  \n",
        "\"n_embd\": 768, # 埋め込み次元（ネットワークの「幅」を決定する）  \n",
        "\"n_head\": 12, # アテンションヘッドの数（n_embdはn_headで割り切れる必要がある）  \n",
        "\"n_layer\": 12 # レイヤーの数（ネットワークの「深さ」を決定する）  \n",
        "}  \n",
        "```"
      ],
      "metadata": {
        "id": "dv8MkBC3mI1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "n_seq = len(inputs) # 入力シーケンスの長さを示す\n",
        "```"
      ],
      "metadata": {
        "id": "TNPovhT_mpTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## パラメータ"
      ],
      "metadata": {
        "id": "oSkf07U2nIny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`params`は、モデルの学習済みの重みを保持するネストされたJSON辞書。JSONの葉ノードはNumPy配列であり、`params`を出力するときに、配列をその形状に置き換える。  \n",
        "  \n",
        "この辞書を参照して、GPTを実装する際に重みの形状を確認するために後で戻ってくる必要がある。コード内の変数名は、この辞書のキーと一致させるたに一貫性を持たせる。"
      ],
      "metadata": {
        "id": "671ltQJInnBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def shape_tree(d):\n",
        "     if isinstance(d, np.ndarray):\n",
        "         return list(d.shape)\n",
        "     elif isinstance(d, list):\n",
        "         return [shape_tree(v) for v in d]\n",
        "     elif isinstance(d, dict):\n",
        "         return {k: shape_tree(v) for k, v in d.items()}\n",
        "     else:\n",
        "         ValueError(\"uh oh\")\n",
        "print(shape_tree(params))\n",
        "```"
      ],
      "metadata": {
        "id": "6YjuC2Unfjil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import tensorflow as tf\n",
        "tf_ckpt_path = tf.train.latest_checkpoint(\"models/124M\")\n",
        "for name, _ in tf.train.list_variables(tf_ckpt_path):\n",
        "    arr = tf.train.load_variable(tf_ckpt_path, name).squeeze()\n",
        "    print(f\"{name}: {arr.shape}\")\n",
        "```"
      ],
      "metadata": {
        "id": "CallsINLfncm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  基本レイヤー"
      ],
      "metadata": {
        "id": "alI67xyYoF6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPTアーキテクチャに入る前に、GPTに固有ではない、いくつかの基本的なニューラルネットワークのレイヤーを実装してみる。"
      ],
      "metadata": {
        "id": "raecHanfoS3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GELU"
      ],
      "metadata": {
        "id": "qMzmMKhgofTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gelu-Reluのグラフに注目すると、このグラフには2つの谷がある。そして勾配が0になるのは x = ±1 付近。  \n",
        "以上から推測すると、この関数は関数の入力を 1 か -1 に近づける勾配成分を持つのではないかと考えられる。（正則化を推進する項が活性化関数に含まれる）  "
      ],
      "metadata": {
        "id": "3UIPPbJEwJV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        ">>> gelu(np.array([[1, 2], [-2, 0.5]]))\n",
        "array([[ 0.84119,  1.9546 ],\n",
        "       [-0.0454 ,  0.34571]])\n",
        "```"
      ],
      "metadata": {
        "id": "AZkOXjzUMpIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))"
      ],
      "metadata": {
        "id": "gZGtPkBTDgh3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ソフトマックス関数"
      ],
      "metadata": {
        "id": "T9Leu_oCyUob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "実数の集合（-∞から∞の間）を確立（0から1の間で、合計が1になる数）に変換するために使用。"
      ],
      "metadata": {
        "id": "rspAXfCcyXSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        ">>> x = softmax(np.array([[2, 100], [-5, 0]]))\n",
        ">>> x\n",
        "array([[0.00034, 0.99966],\n",
        "       [0.26894, 0.73106]])\n",
        ">>> x.sum(axis=-1)\n",
        "array([1., 1.])\n",
        "```"
      ],
      "metadata": {
        "id": "cErj4cnpMlzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)"
      ],
      "metadata": {
        "id": "SRDatFWzfv4z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## レイヤー正規化"
      ],
      "metadata": {
        "id": "Ywsp9Vu6yoWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 名前の通り「レイヤー単位」で，特徴値(グリッド上の各1つの特徴)の正規化を行う．ここでいう「レイヤー(方向での)正規化」とは，RNNで処理している系列中の，\n",
        "番目の隠れ層(レイヤー)の単位で，各隠れにてデータ正規化を行う事をさす．つまりは，「バッチ内における，レイヤーごとの正規化」がレイヤー正規化である。[出典](https://cvml-expertguide.net/terms/dl/layers/batch-normalization-layer/layer-normalization/#4_%E3%81%BE%E3%81%A8%E3%82%81)\n",
        "\n"
      ],
      "metadata": {
        "id": "4VoX-45kyqEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def layer_norm(x, g, b, eps: float = 1e-5):\n",
        "    mean = np.mean(x, axis=-1, keepdims=True)\n",
        "    variance = np.var(x, axis=-1, keepdims=True)\n",
        "    x = (x - mean) / np.sqrt(variance + eps)  # 最後の軸において平均=0、分散=1になるようにxを正規化\n",
        "    return g * x + b  # gamma/betaパラメータでスケールとオフセットを行う"
      ],
      "metadata": {
        "id": "4K60q2ndf1YH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "def layer_norm(x, g, b, eps: float = 1e-5):\n",
        "    mean = np.mean(x, axis=-1, keepdims=True)\n",
        "    variance = np.var(x, axis=-1, keepdims=True)\n",
        "    x = (x - mean) / np.sqrt(variance + eps)  # 最後の軸において平均=0、分散=1になるようにxを正規化\n",
        "    return g * x + b  # gamma/betaパラメータでスケールとオフセットを行う\n",
        "```"
      ],
      "metadata": {
        "id": "PVT5973qMgs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 線形"
      ],
      "metadata": {
        "id": "QRTHegz20E71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "標準的な行列乗算 + バイアス：\n",
        "```python\n",
        "def linear(x, w, b):  # [m, in], [in, out], [out] -> [m, out]\n",
        "    return x @ w + b\n",
        "```"
      ],
      "metadata": {
        "id": "vJisPAAB0G_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear(x, w, b):  # [m, in], [in, out], [out] -> [m, out]\n",
        "    return x @ w + b"
      ],
      "metadata": {
        "id": "mUBzaq5af4fG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPTアーキテクチャ"
      ],
      "metadata": {
        "id": "IYBYazpC0Y2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPTアーキテクチャは、Transformerに従う："
      ],
      "metadata": {
        "id": "BO6SUN2D0ciO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformerについて**\n",
        "  \n",
        "> この文章に含まれる単語のように、連続したデータの関係を追跡することにより、文章ひいては意味を学習するニューラルネットワーク。[出典](https://blogs.nvidia.co.jp/2022/04/13/what-is-a-transformer-model/)\n"
      ],
      "metadata": {
        "id": "cr6OEF0U0i8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "高レベルで、GPTアーキテクチャは3つのセクションを持っています：\n",
        " - テキスト+位置**エンベッディング**\n",
        " - Transformer **デコーダスタック**\n",
        " - **語彙への投影** ステップ\n",
        " コードでは、以下のようになる：\n",
        "```python\n",
        "def gpt2(inputs, wte, wpe, blocks, ln_f, n_head):  # [n_seq] -> [n_seq, n_vocab]\n",
        "    # トークンと位置埋め込みの追加\n",
        "    x = wte[inputs] + wpe[range(len(inputs))]  # [n_seq] -> [n_seq, n_embd]\n",
        "\n",
        "    # n_layer Transformerブロックを通じてのフォワードパス\n",
        "    for block in blocks:\n",
        "        x = transformer_block(x, **block, n_head=n_head)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    # 語彙への射影\n",
        "    x = layer_norm(x, **ln_f)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    return x @ wte.T  # [n_seq, n_embd] -> [n_seq, n_vocab]\n",
        "```"
      ],
      "metadata": {
        "id": "QVzFLo9SDKSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gpt2(inputs, wte, wpe, blocks, ln_f, n_head):  # [n_seq] -> [n_seq, n_vocab]\n",
        "    # トークンと位置埋め込みの追加\n",
        "    x = wte[inputs] + wpe[range(len(inputs))]  # [n_seq] -> [n_seq, n_embd]\n",
        "\n",
        "    # n_layer Transformerブロックを通じてのフォワードパス\n",
        "    for block in blocks:\n",
        "        x = transformer_block(x, **block, n_head=n_head)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    # 語彙への射影\n",
        "    x = layer_norm(x, **ln_f)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    return x @ wte.T  # [n_seq, n_embd] -> [n_seq, n_vocab]"
      ],
      "metadata": {
        "id": "TKNm_H_Nvv8J"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 埋め込み\n"
      ],
      "metadata": {
        "id": "ok1UW3PXFOVW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### トークンの埋め込み"
      ],
      "metadata": {
        "id": "T3NE80bpFWt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "トークンIDの相対的な大きさが誤った情報を伝える恐れがある。また、単一の数値は、ニューラルネットワークが扱うには次元性が十分ではない。そのため、単語ベクトルを利用するが、特に学習された埋め込み行を介す。  \n",
        "**つまり、トレーニングの開始時にランダムに初期化されr、その後勾配降下法を通じて更新される**"
      ],
      "metadata": {
        "id": "oMRL4SfKFZbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "wte[inputs] # [n_seq] -> [n_seq, n_embd]\n",
        "```"
      ],
      "metadata": {
        "id": "2pmU3FpBMag2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 位置埋め込み"
      ],
      "metadata": {
        "id": "Tz9LiIa7H9Un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformerアーキテクチャの特徴の一つは一を考慮しないこと。  \n",
        "**入力をランダムにシャッフルし、出力を適切にアンシャッフルした場合、入力を一切シャッフルしなかった場合と同じ**  \n"
      ],
      "metadata": {
        "id": "6-JPqT3BIDOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "wpe[range(len(inputs))] # [n_seq] -> [n_seq, n_embd]\n",
        "```"
      ],
      "metadata": {
        "id": "ZqHeQH4zMYqT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 組み合わせ"
      ],
      "metadata": {
        "id": "VoJMGjBHIqm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "トークンの一の埋め込みを加算することで、トークンと位置情報の両方をエンコードする組み合わせを得ることができる。"
      ],
      "metadata": {
        "id": "upOCSJJnIsil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# トークン + 位置埋め込み\n",
        "x = wte[inputs] + wpe[range(len(inputs))]  # [n_seq] -> [n_seq, n_embd]\n",
        "\n",
        "# x[i] は i 番目の単語の単語埋め込みと i 番目の位置の位置埋め込みを表します\n",
        "```"
      ],
      "metadata": {
        "id": "1N9xizw7MVCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## デコーダスタック"
      ],
      "metadata": {
        "id": "1DaWwrKBJACQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでディープラーニングに入ってくる。埋め込みを`n_layer`のTransformerデコーダブロックのスタックを通して渡す。  \n",
        "より多くの層を積み重ねることで、ネットワークがどれだけ「深い」かを制御できる。また、`n_embd`値はネットワークがどれだけ「幅広いか」を制御することができる。"
      ],
      "metadata": {
        "id": "3x2AiWwFJC4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# n_layer Transformerブロックを通じた順伝播\n",
        "for block in blocks:\n",
        "    x = transformer_block(x, **block, n_head=n_head)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "```"
      ],
      "metadata": {
        "id": "C7AWJi-zMRbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 語彙への投影"
      ],
      "metadata": {
        "id": "g34pElhsJxkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここで最後のTransformerブロックの出力を5以上の確率分布へ投影する：\n",
        "```python\n",
        "# 語彙への投影\n",
        "x = layer_norm(x, **ln_f)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "return x @ wte.T  # [n_seq, n_embd] -> [n_seq, n_vocab]\n",
        "```\n",
        "  \n",
        "GPTが事前トレーニングされた後、言語モデリングヘッドを何らかの分類タスクのための**分類ヘッド**など、他の種類の投影に交換することが出来る。  \n"
      ],
      "metadata": {
        "id": "U2MTksejJ3nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## デコーダブロック"
      ],
      "metadata": {
        "id": "yfOEIe1MMHOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformerデコーダブロックは、2つのサブレイヤーで構成される：  \n",
        "1. マルチヘッド因果的自己注意\n",
        "2. 位置ごとのフィードフォワードニューラルネットワーク  \n",
        "※各サブレイヤーは入力にレイヤー正規化を利用し残差接続（サブレイヤーの入力をサブレイヤーの出力をサーブレイヤーの出力に加算）を使用：\n",
        "  \n",
        "```python\n",
        "def transformer_block(x, mlp, attn, ln_1, ln_2, n_head):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # マルチヘッド因果的自己注意\n",
        "    x = x + mha(layer_norm(x, **ln_1), **attn, n_head=n_head)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    # 位置ごとのフィードフォワードネットワーク\n",
        "    x = x + ffn(layer_norm(x, **ln_2), **mlp)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    return x\n",
        "```"
      ],
      "metadata": {
        "id": "7WJxj4QYNT1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_block(x, mlp, attn, ln_1, ln_2, n_head):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # マルチヘッド因果的自己注意\n",
        "    x = x + mha(layer_norm(x, **ln_1), **attn, n_head=n_head)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    # 位置ごとのフィードフォワードネットワーク\n",
        "    x = x + ffn(layer_norm(x, **ln_2), **mlp)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "s84frrrYwwvz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**勾配消失問題**とは  \n",
        "    \n",
        "ニューラルネットワークが深くなるほど勾配が小さくなり、重みの更新が十分にされなり学習が停滞してしまう現象のこと。主な原因は、活性化関数と重みの初期値にある。  \n",
        "※勾配とは、損失関数をニューラルネットワークのパラメータ（重み）で微分したもの。ニューラルネットワークは重みが何度も更新されることによって学習が進み完成度を上げる仕組みだが、勾配が小さくなる（ゼロ近づく）と方程式の第2項以降の微分がほぼゼロになり、重みが更新されなくなる。"
      ],
      "metadata": {
        "id": "iz3EVJ2CPCh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 位置ごとのフィードフォワードネットワーク"
      ],
      "metadata": {
        "id": "iBBc1WjJQoxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**フィードフォワードネットワーク（feed forward network）**\n",
        "  \n",
        "入力層から出力層へと一方項に情報が流れるネットワーク構造を持つ。  \n",
        "このネットワークの効果は、中間層における多数のニューロンを通じてデータから特徴を抽出し、それらを組み合わせることにより、より高度なパターンや関係性を学習することである。  \n",
        "[参考：フィードフォワードネットワーク：ディープラーニングの基礎](https://reinforz.co.jp/bizmedia/24900/)  \n",
        "  \n",
        "単なる2層のマルチレイヤ―パーセプトロン：\n",
        "```python\n",
        "def ffn(x, c_fc, c_proj):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # アップへのプロジェクト\n",
        "    a = gelu(linear(x, **c_fc))  # [n_seq, n_embd] -> [n_seq, 4*n_embd]\n",
        "\n",
        "    # ダウンへのプロジェクト\n",
        "    x = linear(a, **c_proj)  # [n_seq, 4*n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    return x\n",
        "```\n"
      ],
      "metadata": {
        "id": "nxGfxZ6GQx9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ffn(x, c_fc, c_proj):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # アップへのプロジェクト\n",
        "    a = gelu(linear(x, **c_fc))  # [n_seq, n_embd] -> [n_seq, 4*n_embd]\n",
        "\n",
        "    # ダウンへのプロジェクト\n",
        "    x = linear(a, **c_proj)  # [n_seq, 4*n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "wIpcKe9Zwy-Q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## マルチヘッド因果自己注意"
      ],
      "metadata": {
        "id": "JmRbW5eJRTHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "各単語に分解して説明することで、この概念を理解しよう：\n",
        "  1. 注意（Attention）\n",
        "  2. 自己（Self）\n",
        "  3. 因果（Causal）\n",
        "  4. マルチヘッド（Multi-Head）\n",
        "  \n",
        "※トークナイザーの語彙(encoder.decoder`に保存されてる)を使用して、実際のトークンがどのように見えるかを確認してるみたいだー\n",
        "```python\n",
        ">>> [encoder.decoder[i] for i in ids]  \n",
        "['注意', '自己', '因果', 'マルチヘッド']  \n",
        "```"
      ],
      "metadata": {
        "id": "h_Ul6JZrRYV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 注意（Attention）"
      ],
      "metadata": {
        "id": "iMDjT91PSi1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaled Dot-Product Attention**  \n",
        "内積を利用したベクトル間の類似性に元ずく返還を行う。入力はQuery、Key、valueの3つ。Queryに基づいてKeyに何らかの変更を施し、valueを取り出す操作をする。  \n",
        "QueryベクトルとKeyの類似性に基づいてValueの各ベクトルの線形結合を計算する。  \n",
        "例えば、KeyとValueには「I have a pen.」を表す行列を、Queryには「have」を表すベクトルを与えると、「have」のベクトルとの類似性に基づいて文章全体の単語ベクトルを用いて線形結合を計算しベクトルを出力する。出力されるベクトルのサイズはQueryのベクトルと同じ。その為、出力ベクトルを単語ベクトルとして考えることができる。これを再帰的に行えば、文章を生成することが可能である。  \n",
        "![](https://developers.agirobots.com/jp/wp-content/uploads/2023/02/image-29-1024x578.png)\n"
      ],
      "metadata": {
        "id": "YqRULEh6Smjk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "def attention(q, k, v):  # [n_q, d_k], [n_k, d_k], [n_k, d_v] -> [n_q, d_v]\n",
        "    return softmax(q @ k.T / np.sqrt(q.shape[-1])) @ v\n",
        "```"
      ],
      "metadata": {
        "id": "zXe3Fug6eNvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(q, k, v):  # [n_q, d_k], [n_k, d_k], [n_k, d_v] -> [n_q, d_v]\n",
        "    return softmax(q @ k.T / np.sqrt(q.shape[-1])) @ v"
      ],
      "metadata": {
        "id": "hPRwi1cb0VJz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 自己（Self）"
      ],
      "metadata": {
        "id": "gwVM6nGgeQwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Query`、`Key`、`Value`がすべて同じソースから来る場合、自己注意を実行：\n",
        "```python\n",
        "def self_attention(x): # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    return attention(q=x, k=x, v=x)\n",
        "```\n",
        "  \n",
        "`Query`、`Key`、`Value`および注意出力のための投影を導入：\n",
        "```python\n",
        "def self_attention(x, w_k, w_q, w_v, w_proj): # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # qkvの投影\n",
        "    q = x @ w_k # [n_seq, n_embd] @ [n_embd, n_embd] -> [n_seq, n_embd]\n",
        "    k = x @ w_q # [n_seq, n_embd] @ [n_embd, n_embd] -> [n_seq, n_embd]\n",
        "    v = x @ w_v # [n_seq, n_embd] @ [n_embd, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    # 自己注意の実行\n",
        "    x = attention(q, k, v) # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    # 出力の投影\n",
        "    x = x @ w_proj # [n_seq, n_embd] @ [n_embd, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    return x\n",
        "```\n",
        "  \n",
        "`w_q`、`w_k`、`w_v@を単一の行列w_fcに組み合わせ、投影を実行し、その結果を分割することで、行列乗算の数を 4 から 2 に減らす：\n",
        "```python\n",
        "def self_attention(x, w_fc, w_proj): # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # qkvの投影\n",
        "    x = x @ w_fc # [n_seq, n_embd] @ [n_embd, 3*n_embd] -> [n_seq, 3*n_embd]\n",
        "\n",
        "    # qkvに分割\n",
        "    q, k, v = np.split(x, 3, axis=-1) # [n_seq, 3*n_embd] -> 3 of [n_seq, n_embd]\n",
        "\n",
        "    # 自己注意の実行\n",
        "    x = attention(q, k, v) # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    # 出力の投影\n",
        "    x = x @ w_proj # [n_seq, n_embd] @ [n_embd, n_embd] = [n_seq, n_embd]\n",
        "\n",
        "    return x\n",
        "```\n",
        "  \n",
        "現代のGPUが連続して発生する3つの小さな行列演算よりも1つの大きな行列乗算をより有効に利用で機少し効率的。\n",
        "  \n",
        "GPT-2 の実装に合わせてバイアスベクトルを追加し、linear関数を使用し、params辞書に合わせてパラメータの名前を変更：\n",
        "```python\n",
        "def self_attention(x, c_attn, c_proj): # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # qkvの投影\n",
        "    x = linear(x, **c_attn) # [n_seq, n_embd] -> [n_seq, 3*n_embd]\n",
        "\n",
        "    # qkvに分割\n",
        "    q, k, v = np.split(x, 3, axis=-1) # [n_seq, 3*n_embd] -> 3 of [n_seq, n_embd]\n",
        "\n",
        "    # 自己注意の実行\n",
        "    x = attention(q, k, v) # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    # 出力の投影\n",
        "    x = linear(x, **c_proj) # [n_seq, n_embd] @ [n_embd, n_embd] = [n_seq, n_embd]\n",
        "\n",
        "    return x\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "-BFlSe6CeWq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 因果（Causl）"
      ],
      "metadata": {
        "id": "VB1DSHGPgAn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "どのような入力を受け取りモデルが学習し出力するか学習時にすでに知っているような状態になってしまわないようにするために、**入力が未来を見ることが出来ないように隠すかマスクする必要がある**。\n",
        "一般に、入力のすべてのクエリが未来を見ることを防ぐ為に、*j > i*であるすべての位置*i*, *j*を`0`に設定する：(これを**マスキング**と呼ぶ)\n",
        "\n",
        "```python\n",
        "       not    all    heroes wear   capes\n",
        "   not 0.116  0.     0.     0.     0.\n",
        "   all 0.180  0.397  0.     0.     0.\n",
        "heroes 0.156  0.453  0.028  0.     0.\n",
        "  wear 0.499  0.055  0.133  0.017  0.\n",
        " capes 0.089  0.290  0.240  0.228  0.153\n",
        " ```\n",
        "   \n",
        "しかし、これは`softmax`が適用後であり、行列の合計が1にならないため、`softmax`が適用される前に注意行列を修正する必要がある。マスクされるエントリを`softmax`の前に$-∞$に設定することで達成可能：\n",
        "\n",
        "```python  \n",
        "def attention(q, k, v, mask):   # [n_q, d_k], [n_k, d_k], [n_k, d_v], [n_q, n_k] -> [n_q, d_v]\n",
        "  return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v\n",
        "```\n",
        "  \n",
        "これらを、すべてまとめると：\n",
        "```python\n",
        "def attention(q, k, v, mask):  # q, k, v はそれぞれクエリ、キー、バリューを表し、mask は注意を適用する範囲を制御します。戻り値は注意後の出力です。\n",
        "    return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v  # スケール済みドット積注意を計算し、適用します。\n",
        "\n",
        "def causal_self_attention(x, c_attn, c_proj):  # x は入力シーケンス、c_attn と c_proj はそれぞれ注意と出力投影のための設定を含む。\n",
        "    # qkv 投影\n",
        "    x = linear(x, **c_attn)  # 入力を線形変換して、q, k, v のための3倍の次元を持つベクトルにします。\n",
        "\n",
        "    # qkv に分割\n",
        "    q, k, v = np.split(x, 3, axis=-1)  # 上記のベクトルを q, k, v に分割します。\n",
        "\n",
        "    # 未来の入力を隠すための因果マスク\n",
        "    causal_mask = (1 - np.tri(x.shape[0]), dtype=x.dtype) * -1e10  # 自己注意で将来の情報が現れないようにするマスクを作成します。\n",
        "\n",
        "    # 因果的自己注意を実行\n",
        "    x = attention(q, k, v, causal_mask)  # 因果的自己注意を適用します。\n",
        "\n",
        "    # 出力投影\n",
        "    x = linear(x, **c_proj)  # 注意後の出力を再び線形変換して最終的な出力を得ます。\n",
        "\n",
        "    return x\n",
        "```"
      ],
      "metadata": {
        "id": "vHkXxqhBgL5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(q, k, v, mask):  # q, k, v はそれぞれクエリ、キー、バリューを表し、mask は注意を適用する範囲を制御します。戻り値は注意後の出力です。\n",
        "    return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v  # スケール済みドット積注意を計算し、適用します。"
      ],
      "metadata": {
        "id": "ZWQle4cz1E5d"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### マルチヘッド"
      ],
      "metadata": {
        "id": "NbIJvjbxiU3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query、Key、Valueを**ヘッド**に分割することで、実装をさらに改善可能：\n",
        "```python\n",
        "def mha(x, c_attn, c_proj, n_head):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # qkvの投影\n",
        "    x = linear(x, **c_attn)  # [n_seq, n_embd] -> [n_seq, 3*n_embd]\n",
        "\n",
        "    # qkvに分割\n",
        "    qkv = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -> [3, n_seq, n_embd]\n",
        "\n",
        "    # ヘッドに分割\n",
        "    qkv_heads = list(map(lambda x: np.split(x, n_head, axis=-1), qkv))  # [3, n_seq, n_embd] -> [3, n_head, n_seq, n_embd/n_head]\n",
        "\n",
        "    # 未来の入力を見ることができないように因果マスクを適用\n",
        "    causal_mask = (1 - np.tri(x.shape[0]), dtype=x.dtype) * -1e10  # [n_seq, n_seq]\n",
        "\n",
        "    # 各ヘッドで注意を実行\n",
        "    out_heads = [attention(q, k, v, causal_mask) for q, k, v in zip(*qkv_heads)]  # [3, n_head, n_seq, n_embd/n_head] -> [n_head, n_seq, n_embd/n_head]\n",
        "\n",
        "    # ヘッドを結合\n",
        "    x = np.hstack(out_heads)  # [n_head, n_seq, n_embd/n_head] -> [n_seq, n_embd]\n",
        "\n",
        "    # 出力の投影\n",
        "    x = linear(x, **c_proj)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    return x\n",
        "```\n",
        "  \n",
        "1. `Query`、`Kev`、`Value`を分割\n",
        "2. 各ヘッドに対して注意を計算\n",
        "3. 出力の結合\n",
        "  \n",
        "これにより、次元が減少するが、モデルはAttentionを通じて関係をモデリングする際に、追加の*部分空間*を利用できる。\n"
      ],
      "metadata": {
        "id": "TT3nJ60diXDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mha(x, c_attn, c_proj, n_head):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # qkvの投影\n",
        "    x = linear(x, **c_attn)  # [n_seq, n_embd] -> [n_seq, 3*n_embd]\n",
        "\n",
        "    # qkvに分割\n",
        "    qkv = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -> [3, n_seq, n_embd]\n",
        "\n",
        "    # ヘッドに分割\n",
        "    qkv_heads = list(map(lambda x: np.split(x, n_head, axis=-1), qkv))  # [3, n_seq, n_embd] -> [3, n_head, n_seq, n_embd/n_head]\n",
        "\n",
        "    # 未来の入力を見ることができないように因果マスクを適用\n",
        "    # causal_mask = (1 - np.tri(x.shape[0]), dtype=x.dtype) * -1e10  # [n_seq, n_seq]\n",
        "    causal_mask = (1 - np.tri(x.shape[0], dtype=x.dtype)) * -1e10  # [n_seq, n_seq]\n",
        "\n",
        "    # 各ヘッドで注意を実行\n",
        "    out_heads = [attention(q, k, v, causal_mask) for q, k, v in zip(*qkv_heads)]  # [3, n_head, n_seq, n_embd/n_head] -> [n_head, n_seq, n_embd/n_head]\n",
        "\n",
        "    # ヘッドを結合\n",
        "    x = np.hstack(out_heads)  # [n_head, n_seq, n_embd/n_head] -> [n_seq, n_embd]\n",
        "\n",
        "    # 出力の投影\n",
        "    x = linear(x, **c_proj)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "sAUmUEWK1Hwl"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(inputs, params, n_head, n_tokens_to_generate):\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    for _ in tqdm(range(n_tokens_to_generate), \"generating\"):  # 自己回帰デコードループ\n",
        "        logits = gpt2(inputs, **params, n_head=n_head)  # モデルのフォワードパス\n",
        "        next_id = np.argmax(logits[-1])  # 貪欲サンプリング\n",
        "        inputs.append(int(next_id))  # 予測を入力に追加\n",
        "\n",
        "    return inputs[len(inputs) - n_tokens_to_generate :]  # 生成されたidのみを返す"
      ],
      "metadata": {
        "id": "N7_H63KRFgqx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(prompt: str, n_tokens_to_generate: int = 40, model_size: str = \"124M\", models_dir: str = \"models\"):\n",
        "    from utils import load_encoder_hparams_and_params\n",
        "\n",
        "    # 公開されているOpenAI GPT-2ファイルからエンコーダー、hparams、およびparamsを読み込む\n",
        "    encoder, hparams, params = load_encoder_hparams_and_params(model_size, models_dir)\n",
        "\n",
        "    # BPEトークナイザーを使用して入力文字列をエンコードする\n",
        "    input_ids = encoder.encode(prompt)\n",
        "\n",
        "    # モデルの最大シーケンス長を超えないようにする\n",
        "    assert len(input_ids) + n_tokens_to_generate < hparams[\"n_ctx\"]\n",
        "\n",
        "    # 出力idを生成する\n",
        "    output_ids = generate(input_ids, params, hparams[\"n_head\"], n_tokens_to_generate)\n",
        "\n",
        "    # idを文字列にデコードする\n",
        "    output_text = encoder.decode(output_ids)\n",
        "\n",
        "    return output_text"
      ],
      "metadata": {
        "id": "7sZRgJeFhMmC"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 最後にすべてをまとめて実行"
      ],
      "metadata": {
        "id": "m9_BkEFrsKgT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでは例として与える文字列を  \n",
        "\"Alan Turing theorized that computers would one day become\" としている。  \n",
        "ここで、出力は  \n",
        "the most powerful machines on the planet.  \n",
        "が返ってくれば成功！"
      ],
      "metadata": {
        "id": "5glVzcQIsW9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gelu(x):\n",
        "    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * x**3)))\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
        "\n",
        "\n",
        "def layer_norm(x, g, b, eps: float = 1e-5):\n",
        "    mean = np.mean(x, axis=-1, keepdims=True)\n",
        "    variance = np.var(x, axis=-1, keepdims=True)\n",
        "    x = (x - mean) / np.sqrt(variance + eps)  # 最後の軸において平均=0、分散=1になるようにxを正規化\n",
        "    return g * x + b  # gamma/betaパラメータでスケールとオフセットを行う\n",
        "\n",
        "\n",
        "def linear(x, w, b):  # [m, in], [in, out], [out] -> [m, out]\n",
        "    return x @ w + b\n",
        "\n",
        "\n",
        "def ffn(x, c_fc, c_proj):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # アップへのプロジェクト\n",
        "    a = gelu(linear(x, **c_fc))  # [n_seq, n_embd] -> [n_seq, 4*n_embd]\n",
        "\n",
        "    # ダウンへのプロジェクト\n",
        "    x = linear(a, **c_proj)  # [n_seq, 4*n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def attention(q, k, v, mask):  # q, k, v はそれぞれクエリ、キー、バリューを表し、mask は注意を適用する範囲を制御します。戻り値は注意後の出力です。\n",
        "    return softmax(q @ k.T / np.sqrt(q.shape[-1]) + mask) @ v  # スケール済みドット積注意を計算し、適用します。\n",
        "\n",
        "\n",
        "def mha(x, c_attn, c_proj, n_head):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # qkvの投影\n",
        "    x = linear(x, **c_attn)  # [n_seq, n_embd] -> [n_seq, 3*n_embd]\n",
        "\n",
        "    # qkvに分割\n",
        "    qkv = np.split(x, 3, axis=-1)  # [n_seq, 3*n_embd] -> [3, n_seq, n_embd]\n",
        "\n",
        "    # ヘッドに分割\n",
        "    qkv_heads = list(map(lambda x: np.split(x, n_head, axis=-1), qkv))  # [3, n_seq, n_embd] -> [3, n_head, n_seq, n_embd/n_head]\n",
        "\n",
        "    # 未来の入力を見ることができないように因果マスクを適用\n",
        "    # causal_mask = (1 - np.tri(x.shape[0]), dtype=x.dtype) * -1e10  # [n_seq, n_seq]\n",
        "    causal_mask = (1 - np.tri(x.shape[0], dtype=x.dtype)) * -1e10  # [n_seq, n_seq]\n",
        "\n",
        "    # 各ヘッドで注意を実行\n",
        "    out_heads = [attention(q, k, v, causal_mask) for q, k, v in zip(*qkv_heads)]  # [3, n_head, n_seq, n_embd/n_head] -> [n_head, n_seq, n_embd/n_head]\n",
        "\n",
        "    # ヘッドを結合\n",
        "    x = np.hstack(out_heads)  # [n_head, n_seq, n_embd/n_head] -> [n_seq, n_embd]\n",
        "\n",
        "    # 出力の投影\n",
        "    x = linear(x, **c_proj)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def transformer_block(x, mlp, attn, ln_1, ln_2, n_head):  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    # マルチヘッド因果的自己注意\n",
        "    x = x + mha(layer_norm(x, **ln_1), **attn, n_head=n_head)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    # 位置ごとのフィードフォワードネットワーク\n",
        "    x = x + ffn(layer_norm(x, **ln_2), **mlp)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def gpt2(inputs, wte, wpe, blocks, ln_f, n_head):  # [n_seq] -> [n_seq, n_vocab]\n",
        "    # トークンと位置埋め込みの追加\n",
        "    x = wte[inputs] + wpe[range(len(inputs))]  # [n_seq] -> [n_seq, n_embd]\n",
        "\n",
        "    # n_layer Transformerブロックを通じてのフォワードパス\n",
        "    for block in blocks:\n",
        "        x = transformer_block(x, **block, n_head=n_head)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "\n",
        "    # 語彙への射影\n",
        "    x = layer_norm(x, **ln_f)  # [n_seq, n_embd] -> [n_seq, n_embd]\n",
        "    return x @ wte.T  # [n_seq, n_embd] -> [n_seq, n_vocab]\n",
        "\n",
        "\n",
        "def generate(inputs, params, n_head, n_tokens_to_generate):\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    for _ in tqdm(range(n_tokens_to_generate), \"generating\"):  # 自己回帰デコードループ\n",
        "        logits = gpt2(inputs, **params, n_head=n_head)  # モデルのフォワードパス\n",
        "        next_id = np.argmax(logits[-1])  # 貪欲サンプリング\n",
        "        inputs.append(int(next_id))  # 予測を入力に追加\n",
        "\n",
        "    return inputs[len(inputs) - n_tokens_to_generate :]  # 生成されたidのみを返す\n",
        "\n",
        "\n",
        "def main(prompt: str, n_tokens_to_generate: int = 40, model_size: str = \"124M\", models_dir: str = \"models\"):\n",
        "    from utils import load_encoder_hparams_and_params\n",
        "\n",
        "    # 公開されているOpenAI GPT-2ファイルからエンコーダー、hparams、およびparamsを読み込む\n",
        "    encoder, hparams, params = load_encoder_hparams_and_params(model_size, models_dir)\n",
        "\n",
        "    # BPEトークナイザーを使用して入力文字列をエンコードする\n",
        "    input_ids = encoder.encode(prompt)\n",
        "\n",
        "    # モデルの最大シーケンス長を超えないようにする\n",
        "    assert len(input_ids) + n_tokens_to_generate < hparams[\"n_ctx\"]\n",
        "\n",
        "    # 出力idを生成する\n",
        "    output_ids = generate(input_ids, params, hparams[\"n_head\"], n_tokens_to_generate)\n",
        "\n",
        "    # idを文字列にデコードする\n",
        "    output_text = encoder.decode(output_ids)\n",
        "\n",
        "    return output_text\n",
        "\n",
        "main(\"Alan Turing theorized that computers would one day become\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mNHtB311rnyB",
        "outputId": "d04112ae-7746-480e-93c5-dcf95558e739"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "generating: 100%|██████████| 40/40 [00:16<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' the most powerful machines on the planet.\\n\\nThe computer is a machine that can perform complex calculations, and it can perform these calculations in a way that is very similar to the human brain.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pythonスクリプトとして起動された場合のみ配下の処理が実行  \n",
        "```python\n",
        "if __name__ = \"__main___\":\n",
        "  import fire\n",
        "  fire.Fire(main)\n",
        "```"
      ],
      "metadata": {
        "id": "aeJCMQ0xmxtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# その他 memo\n",
        "\n"
      ],
      "metadata": {
        "id": "AQ1zc5_h2vnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  基本的な変数の型[イミュータブル]"
      ],
      "metadata": {
        "id": "nRLPYiSe29MR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "<変数名>:<型>\n",
        "<変数名>:<型> = <初期値>\n",
        "```"
      ],
      "metadata": {
        "id": "AVJD0vz93dg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 関数の型  "
      ],
      "metadata": {
        "id": "dYB3p0e72_wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "基本形\n",
        "\n",
        "```\n",
        "def <関数名>(<関数名>: <型>) -> <戻り値の型>:\n",
        "\t...\n",
        "```\n",
        "実査に使う場合以下のようになる\n",
        "```python\n",
        "def add(x: int, y: int) -> int:\n",
        "\treturn x + y\n",
        "```\n",
        "戻り値がない関数の場合は、戻り値の型をNoneとして設定する。\n",
        "```python\n",
        "def log_print(number: int) -> None:\n",
        "\tprint('値は{}です'.format(number))\n",
        "\n",
        "b = log_pirnt(12) # mypy error\n",
        "```"
      ],
      "metadata": {
        "id": "VMneyXrU3gVL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 配列の最大要素のインデックスを返すNumPyのargmax関数の使い方"
      ],
      "metadata": {
        "id": "V1Mdaacd3JoW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[参考サイト](https://deepage.net/features/numpy-argmax.html)\n",
        "NumPyのargmax関数は、**多次元配列の中の最大値の要素を持つインデックスを返す関数**。`np.max`を使うと、最大値の要素を返すことができる。`argmax`は、最大の要素のインデックスを返す。\n",
        "```python\n",
        "np.argmax(a, axis = None, out = None)\n",
        "```\n",
        "使い方\n",
        "`np.argmax`は、第一引数に最大値を取得したい配列を指定。また、最後の引数の`out`はあまり使用しない。出力の配列を予め作っておいた配列にしたい場合は指定する。\n",
        "※最小のインデックスを取得したい場合は `argmin` を使うことで取得可能\n",
        "- 次元が増えると考えるのが少し難しくなる"
      ],
      "metadata": {
        "id": "FtQM35Gd3joE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### インデックスのスライスの基本"
      ],
      "metadata": {
        "id": "pO4A2-Cl3swI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[参考サイト](https://atmarkit.itmedia.co.jp/ait/articles/2012/08/news013.html)\n",
        "```python\n",
        "mylist = list[range(10)]\n",
        "print(mylist) # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "# インデックスによるアクセス  \n",
        "n = mylist[1]  # 正数は先頭からのインデックス。先頭の要素のインデックスが0  \n",
        "print(n)  # 1  \n",
        "n = mylist[-2]  # 負数は末尾からのインデックス。末尾の要素のインデックスが-1\n",
        "print(n)  # 8  \n",
        "  \n",
        "# スライスによるアクセス  \n",
        "mylist = list(range(10))  \n",
        "  \n",
        "s = mylist[0:5]  # 0～4番目の5要素を取り出す  \n",
        "print(s)  # [0, 1, 2, 3, 4]\n",
        "```\n",
        "pythonでは、ほかの言語における配列はリストとして実装されているため、その要素にはインデックスやスライスといった機構を通じてアクセスできる。規範は以下\n",
        "- インデックス：かっこ`[]`内にアクセスしたい要素のインデックスを指定\n",
        "- スライス：かっこ`[]`内にアクセスしたい要素の範囲を「**lower_bound:upper_bound:stride**」のかたちで記述\n",
        "  lower_boundはリストの中でスライスの始まる位置\n",
        "  upper_boundはスライスの終わる位置\n",
        "  strideは増分（いずれも省略可）"
      ],
      "metadata": {
        "id": "50lhBtgG3vqS"
      }
    }
  ]
}